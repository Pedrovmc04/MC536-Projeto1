{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9260742a",
   "metadata": {},
   "source": [
    "# Database Execution Notebook MC536 Project\n",
    "\n",
    "This notebook is divided into sections for importing requirements, creating the database and tables, and adding data to the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886348f0",
   "metadata": {},
   "source": [
    "## 1. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f781264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "# Database configuration parameters\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'my_database',  # Replace with your database name\n",
    "    'user': 'postgres',         # Replace with your username\n",
    "    'password': 'mypassword',     # Replace with your password\n",
    "    'host': '127.0.0.1',\n",
    "    'port': '5433'\n",
    "}\n",
    "\n",
    "# Path configuration for csv files\n",
    "DATA_DIR = './data'\n",
    "\n",
    "# Path to the SQL script for creating the database\n",
    "DB_script_path = './DB_creation_script.sql'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07718611",
   "metadata": {},
   "source": [
    "## 2. Connecting to Database Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38fb8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to connect to PostgreSQL - updated to set encoding\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        conn.set_client_encoding('UTF8')  # Set connection encoding to UTF-8\n",
    "        print(\"Connected to PostgreSQL database successfully\")\n",
    "        return conn\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(f\"Error while connecting to PostgreSQL: {error}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d324271",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Inserting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05d6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize accented text\n",
    "def normalize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    # Normalize accented characters properly\n",
    "    return text.strip()\n",
    "\n",
    "# Function to load CAPACIDADE_GERACAO.csv\n",
    "def load_capacidade_geracao():\n",
    "    file_path = os.path.join(DATA_DIR, 'CAPACIDADE_GERACAO.csv')\n",
    "    try:\n",
    "        # Try multiple encodings to find the correct one\n",
    "        encodings = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']\n",
    "        \n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                print(f\"Attempting to read with encoding: {encoding}\")\n",
    "                # Read CSV with the specified encoding\n",
    "                df = pd.read_csv(file_path, delimiter=';', encoding=encoding)\n",
    "                \n",
    "                # Replace empty strings and 'NULL' with None\n",
    "                df = df.replace(['', 'NULL'], None)\n",
    "                \n",
    "                # Normalize text in all string columns to handle accents properly\n",
    "                for col in df.select_dtypes(include=['object']).columns:\n",
    "                    df[col] = df[col].apply(normalize_text)\n",
    "                \n",
    "                # Convert date columns to datetime\n",
    "                for date_col in ['dat_entradateste', 'dat_entradaoperacao', 'dat_desativacao']:\n",
    "                    if date_col in df.columns:\n",
    "                        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                \n",
    "                # Convert potencia_efetiva to float\n",
    "                if 'val_potenciaefetiva' in df.columns:\n",
    "                    df['val_potenciaefetiva'] = pd.to_numeric(df['val_potenciaefetiva'], errors='coerce')\n",
    "                \n",
    "                print(f\"Successfully loaded data with encoding: {encoding}\")\n",
    "                return df\n",
    "                \n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to decode with {encoding}, trying next encoding...\")\n",
    "        \n",
    "        raise Exception(\"Could not read the file with any of the attempted encodings\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CAPACIDADE_GERACAO.csv: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Function to load country data files\n",
    "def load_country_data(file_name, value_column_name):\n",
    "    file_path = os.path.join(DATA_DIR, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Extract relevant columns\n",
    "        df = df[['Entity', 'Code', 'Year', value_column_name]]\n",
    "        \n",
    "        # Rename columns for consistency\n",
    "        df = df.rename(columns={\n",
    "            'Entity': 'nome_pais',\n",
    "            'Code': 'code',\n",
    "            'Year': 'ano',\n",
    "            value_column_name: 'valor'\n",
    "        })\n",
    "        \n",
    "        # Convert numeric values\n",
    "        df['ano'] = pd.to_numeric(df['ano'], errors='coerce')\n",
    "        df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "        \n",
    "        # Remove rows with NaN in code field\n",
    "        df = df.dropna(subset=['code'])\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_name}: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Function to insert regiao data\n",
    "def insert_subsistema(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get the country id for Brazil\n",
    "        cursor.execute(\"SELECT id_pais FROM Pais WHERE nome LIKE '%Brazil%' OR nome LIKE '%Brasil%' LIMIT 1\")\n",
    "        brasil_id = cursor.fetchone()\n",
    "        \n",
    "        if not brasil_id:\n",
    "            # If Brazil doesn't exist, insert it\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO Pais (code, nome)\n",
    "                VALUES (%s, %s)\n",
    "                RETURNING id_pais\n",
    "                \"\"\",\n",
    "                ('BRA', 'Brazil')\n",
    "            )\n",
    "            brasil_id = cursor.fetchone()\n",
    "        \n",
    "        # Extract unique regions from the dataset using id_subsistema and nom_subsistema\n",
    "        subsistemas_df = df[['id_subsistema', 'nom_subsistema']].drop_duplicates()\n",
    "        subsistemas_ids = {}\n",
    "        \n",
    "        # Insert each unique region\n",
    "        for _, row in subsistemas_df.iterrows():\n",
    "            cod_subsistema = row['id_subsistema']  # Changed from cod_regiao to cod_subsistema\n",
    "            nome = row['nom_subsistema']\n",
    "            \n",
    "            # First check if region already exists\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT id_subsistema FROM Subsistema WHERE cod_subsistema = %s\n",
    "                \"\"\",\n",
    "                (cod_subsistema,)\n",
    "            )\n",
    "            existing = cursor.fetchone()\n",
    "            \n",
    "            if existing:\n",
    "                # Region exists, update if needed\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    UPDATE Subsistema SET nome = %s WHERE cod_subsistema = %s\n",
    "                    RETURNING id_subsistema\n",
    "                    \"\"\",\n",
    "                    (nome, cod_subsistema)\n",
    "                )\n",
    "                subsistema_id = cursor.fetchone()[0]\n",
    "                subsistemas_ids[nome] = subsistema_id\n",
    "            else:\n",
    "                # Insert new region\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Subsistema (cod_subsistema, nome, id_pais)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    RETURNING id_subsistema\n",
    "                    \"\"\",\n",
    "                    (cod_subsistema, nome, brasil_id[0])\n",
    "                )\n",
    "                subsistema_id = cursor.fetchone()[0]\n",
    "                subsistemas_ids[cod_subsistema] = subsistema_id\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Inserted/updated {len(subsistemas_ids)} subsistemas\")\n",
    "        \n",
    "        return subsistemas_ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Subsistema: {e}\")\n",
    "        conn.rollback()\n",
    "        return {}\n",
    "\n",
    "# Function to insert estado and subsistema_estado data\n",
    "def insert_estado_and_subsistema_estado(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Extract unique states from the dataset\n",
    "        estados_df = df[['id_estado', 'nom_estado']].drop_duplicates()\n",
    "        estados_ids = {}\n",
    "        \n",
    "        # Insert each unique state\n",
    "        for _, row in estados_df.iterrows():\n",
    "            cod_estado = row['id_estado']  # Use id_estado from the DataFrame as cod_estado in the database\n",
    "            nome_estado = row['nom_estado']\n",
    "            \n",
    "            # First check if the state already exists\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT id_estado FROM Estado WHERE cod_estado = %s\n",
    "                \"\"\",\n",
    "                (cod_estado,)\n",
    "            )\n",
    "            existing = cursor.fetchone()\n",
    "            \n",
    "            if existing:\n",
    "                # State exists, update if needed\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    UPDATE Estado SET nome = %s WHERE cod_estado = %s\n",
    "                    RETURNING id_estado\n",
    "                    \"\"\",\n",
    "                    (nome_estado, cod_estado)\n",
    "                )\n",
    "                estado_id = cursor.fetchone()[0]\n",
    "                estados_ids[cod_estado] = estado_id\n",
    "            else:\n",
    "                # Insert new state\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Estado (cod_estado, nome)\n",
    "                    VALUES (%s, %s)\n",
    "                    RETURNING id_estado\n",
    "                    \"\"\",\n",
    "                    (cod_estado, nome_estado)\n",
    "                )\n",
    "                estado_id = cursor.fetchone()[0]\n",
    "                estados_ids[cod_estado] = estado_id\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Inserted/updated {len(estados_ids)} states\")\n",
    "        \n",
    "        # Insert Subsistemas\n",
    "        subsistemas_ids = insert_subsistema(conn, df)\n",
    "        \n",
    "        # Insert into Subsistema_Estado table\n",
    "        subsistema_estado_df = df[['id_estado', 'id_subsistema']].drop_duplicates()\n",
    "        subsistema_estado_ids = {}\n",
    "        \n",
    "        for _, row in subsistema_estado_df.iterrows():\n",
    "            cod_estado = row['id_estado']  # Use id_estado from the DataFrame as cod_estado in the database\n",
    "            cod_subsistema = row['id_subsistema'] # Use id_subsistema from the DataFrame as cod_subsistema in the database\n",
    "            \n",
    "            # Get the artificial primary key for the state\n",
    "            estado_id = estados_ids.get(cod_estado)\n",
    "            subsistema_id = subsistemas_ids.get(cod_subsistema)\n",
    "            \n",
    "            \n",
    "            if estado_id:\n",
    "                # Check if the relationship already exists\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT id_estado, id_subsistema FROM Subsistema_Estado\n",
    "                    WHERE id_estado = %s AND id_subsistema = %s\n",
    "                    \"\"\",\n",
    "                    (estado_id, subsistema_id)\n",
    "                )\n",
    "                existing = cursor.fetchone()\n",
    "                \n",
    "                if not existing:\n",
    "                    # Insert new relationship\n",
    "                    cursor.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT INTO Subsistema_Estado (id_estado, id_subsistema)\n",
    "                        VALUES (%s, %s)\n",
    "                        RETURNING id_estado, id_subsistema\n",
    "                        \"\"\",\n",
    "                        (estado_id, subsistema_id)\n",
    "                    )\n",
    "                    subsistema_estado_ids[(estado_id, subsistema_id)] = cursor.fetchone()\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Inserted/updated {len(subsistema_estado_ids)} subsistema-estado relationships\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Estado and Subsistema_Estado: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "# Function to insert data into Agente_Proprietario table\n",
    "def insert_agentes(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Extract unique agents from the dataframe\n",
    "        agentes = df['nom_agenteproprietario'].dropna().unique()\n",
    "        \n",
    "        for agente in agentes:\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO Agente_Proprietario (nome)\n",
    "                VALUES (%s)\n",
    "                ON CONFLICT DO NOTHING\n",
    "                \"\"\",\n",
    "                (agente,)\n",
    "            )\n",
    "            \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {len(agentes)} agents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Agente_Proprietario: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "# Function to insert data into Usina table\n",
    "def insert_usinas(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        inserted = 0\n",
    "        \n",
    "        # First, get mappings for foreign keys\n",
    "        cursor.execute(\"SELECT id_estado, cod_estado FROM Estado\")\n",
    "        estado_map = {cod: id for id, cod in cursor.fetchall()}\n",
    "        \n",
    "        cursor.execute(\"SELECT id_agente, nome FROM Agente_Proprietario\")\n",
    "        agente_map = {nome: id for id, nome in cursor.fetchall()}\n",
    "        \n",
    "        # Group by unique usina - now including the ceg field\n",
    "        usinas = df[['nom_usina', 'nom_agenteproprietario', 'nom_tipousina',\n",
    "                     'nom_modalidadeoperacao', 'id_estado', 'ceg']].drop_duplicates()\n",
    "        \n",
    "        for _, row in usinas.iterrows():\n",
    "            id_agente = agente_map.get(row['nom_agenteproprietario'])\n",
    "            id_estado = estado_map.get(row['id_estado'])\n",
    "            \n",
    "            # Ensure proper handling of accented characters\n",
    "            tipo_usina = row['nom_tipousina'].strip() if isinstance(row['nom_tipousina'], str) else row['nom_tipousina']\n",
    "            modalidade = row['nom_modalidadeoperacao'].strip() if isinstance(row['nom_modalidadeoperacao'], str) else row['nom_modalidadeoperacao']\n",
    "            nome_usina = row['nom_usina'].strip() if isinstance(row['nom_usina'], str) else row['nom_usina']\n",
    "            ceg = row['ceg'].strip() if isinstance(row['ceg'], str) else row['ceg']\n",
    "            \n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO Usina (nome, id_agente_proprietario, tipo,\n",
    "                                  modalidade_operacao, id_estado, ceg)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT DO NOTHING\n",
    "                RETURNING id_usina\n",
    "                \"\"\",\n",
    "                (nome_usina, id_agente, tipo_usina, modalidade, id_estado, ceg)\n",
    "            )\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                inserted += 1\n",
    "                \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} power plants\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Usina: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "# Function to insert data into Unidade_Geradora table\n",
    "def insert_unidades_geradoras(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        inserted = 0\n",
    "        \n",
    "        # Get usina mapping\n",
    "        cursor.execute(\"SELECT id_usina, nome FROM Usina\")\n",
    "        usina_map = {nome: id for id, nome in cursor.fetchall()}\n",
    "        \n",
    "        # Extract units - now including date fields that were moved from Usina\n",
    "        unidades = df[['nom_usina', 'cod_equipamento', 'nom_unidadegeradora',\n",
    "                      'num_unidadegeradora', 'dat_entradateste', 'dat_entradaoperacao',\n",
    "                      'dat_desativacao', 'val_potenciaefetiva', \n",
    "                      'nom_combustivel']].drop_duplicates()\n",
    "        \n",
    "        for _, row in unidades.iterrows():\n",
    "            id_usina = usina_map.get(row['nom_usina'])\n",
    "            \n",
    "            # Convert num_unidadegeradora to integer safely\n",
    "            try:\n",
    "                num_unidade = int(row['num_unidadegeradora'])\n",
    "            except (ValueError, TypeError):\n",
    "                # If conversion fails, set to None\n",
    "                num_unidade = None\n",
    "            \n",
    "            # Handle NaT/None values for date columns\n",
    "            data_teste = None if pd.isna(row['dat_entradateste']) else row['dat_entradateste']\n",
    "            data_operacao = None if pd.isna(row['dat_entradaoperacao']) else row['dat_entradaoperacao']\n",
    "            data_desativacao = None if pd.isna(row['dat_desativacao']) else row['dat_desativacao']\n",
    "            \n",
    "            # Handle accented characters properly\n",
    "            combustivel = row['nom_combustivel'].strip() if isinstance(row['nom_combustivel'], str) else row['nom_combustivel']\n",
    "            nome_unidade = row['nom_unidadegeradora'].strip() if isinstance(row['nom_unidadegeradora'], str) else row['nom_unidadegeradora']\n",
    "            cod_equip = row['cod_equipamento'].strip() if isinstance(row['cod_equipamento'], str) else row['cod_equipamento']\n",
    "            \n",
    "            if id_usina:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Unidade_Geradora (cod_equipamento, nome_unidade,\n",
    "                                               num_unidade, data_entrada_teste,\n",
    "                                               data_entrada_operacao, data_desativacao,\n",
    "                                               potencia_efetiva, combustivel, id_usina)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                    RETURNING id_unidade\n",
    "                    \"\"\",\n",
    "                    (cod_equip, nome_unidade,\n",
    "                     num_unidade, data_teste, data_operacao,\n",
    "                     data_desativacao, row['val_potenciaefetiva'],\n",
    "                     combustivel, id_usina)\n",
    "                )\n",
    "                \n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    inserted += 1\n",
    "                    \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} generating units\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Unidade_Geradora: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "# Function to insert data into Pais table\n",
    "def insert_paises(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Extract unique countries and ensure code is not NaN\n",
    "        paises = df[['nome_pais', 'code']].dropna(subset=['code']).drop_duplicates()\n",
    "        \n",
    "        inserted = 0\n",
    "        country_ids = {}  # Dictionary to store code -> id_pais mapping\n",
    "        \n",
    "        for _, row in paises.iterrows():\n",
    "            # First check if country exists\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT id_pais FROM Pais WHERE code = %s\n",
    "                \"\"\",\n",
    "                (row['code'],)\n",
    "            )\n",
    "            existing = cursor.fetchone()\n",
    "            \n",
    "            if existing:\n",
    "                country_ids[row['code']] = existing[0]\n",
    "            else:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Pais (code, nome)\n",
    "                    VALUES (%s, %s)\n",
    "                    RETURNING id_pais\n",
    "                    \"\"\",\n",
    "                    (row['code'], row['nome_pais'])\n",
    "                )\n",
    "                \n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    inserted += 1\n",
    "                    country_ids[row['code']] = result[0]\n",
    "                \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} countries\")\n",
    "        return country_ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Pais: {e}\")\n",
    "        conn.rollback()\n",
    "        return {}\n",
    "    \n",
    "# Function to insert data into a specified table\n",
    "def insert_country_data(conn, df, table_name):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        inserted = 0\n",
    "        \n",
    "        # Filter out rows with NaN codes\n",
    "        df_clean = df.dropna(subset=['code'])\n",
    "        \n",
    "        # Get country_id mapping\n",
    "        country_ids = {}\n",
    "        cursor.execute(\"SELECT id_pais, code FROM Pais\")\n",
    "        for id_pais, code in cursor.fetchall():\n",
    "            country_ids[code] = id_pais\n",
    "        \n",
    "        for _, row in df_clean.iterrows():\n",
    "            code = row['code']\n",
    "            id_pais = country_ids.get(code)\n",
    "            \n",
    "            if id_pais:\n",
    "                cursor.execute(\n",
    "                    f\"\"\"\n",
    "                    INSERT INTO {table_name} (id_pais, ano, porcentagem)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                    RETURNING id\n",
    "                    \"\"\",\n",
    "                    (id_pais, row['ano'], row['valor'])\n",
    "                )\n",
    "                \n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    inserted += 1\n",
    "            else:\n",
    "                print(f\"Warning: No country ID found for code {code}\")\n",
    "                \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} records into {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into {table_name}: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "\n",
    "# Function to insert investment data\n",
    "def insert_investment_data(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        inserted = 0\n",
    "        \n",
    "        # Filter out rows with NaN codes\n",
    "        df_clean = df.dropna(subset=['code'])\n",
    "        \n",
    "        # Get country_id mapping\n",
    "        country_ids = {}\n",
    "        cursor.execute(\"SELECT id_pais, code FROM Pais\")\n",
    "        for id_pais, code in cursor.fetchall():\n",
    "            country_ids[code] = id_pais\n",
    "            \n",
    "        for _, row in df_clean.iterrows():\n",
    "            code = row['code']\n",
    "            id_pais = country_ids.get(code)\n",
    "            \n",
    "            if id_pais:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Investimento_Energia_Limpa (id_pais, ano, valor_dolar)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                    RETURNING id\n",
    "                    \"\"\",\n",
    "                    (id_pais, row['ano'], row['valor'])\n",
    "                )\n",
    "                \n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    inserted += 1\n",
    "            else:\n",
    "                print(f\"Warning: No country ID found for code {code}\")\n",
    "                \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} investment records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Investimento_Energia_Limpa: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "        \n",
    "# Function to insert renewable per capita data\n",
    "def insert_renewable_per_capita(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        inserted = 0\n",
    "        \n",
    "        # Filter out rows with NaN codes\n",
    "        df_clean = df.dropna(subset=['code'])\n",
    "        \n",
    "        # Get country_id mapping\n",
    "        country_ids = {}\n",
    "        cursor.execute(\"SELECT id_pais, code FROM Pais\")\n",
    "        for id_pais, code in cursor.fetchall():\n",
    "            country_ids[code] = id_pais\n",
    "        \n",
    "        for _, row in df_clean.iterrows():\n",
    "            code = row['code']\n",
    "            id_pais = country_ids.get(code)\n",
    "            \n",
    "            if id_pais:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Energia_Renovavel_Per_Capita (id_pais, ano, geracao_watts)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                    RETURNING id\n",
    "                    \"\"\",\n",
    "                    (id_pais, row['ano'], row['valor'])\n",
    "                )\n",
    "                \n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    inserted += 1\n",
    "            else:\n",
    "                print(f\"Warning: No country ID found for code {code}\")\n",
    "                \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} renewable per capita records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into Energia_Renovavel_Per_Capita: {e}\")\n",
    "        conn.rollback()\n",
    "        \n",
    "        \n",
    "# Function to load and process HDI data\n",
    "def load_hdi_data():\n",
    "    file_path = os.path.join(DATA_DIR, 'HDR23-24_Composite_indices_complete_time_series.csv')\n",
    "    \n",
    "    # List of encodings to try\n",
    "    encodings = ['latin-1', 'ISO-8859-1', 'cp1252', 'utf-8-sig']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            print(f\"Trying to read HDI data with encoding: {encoding}\")\n",
    "            # Read CSV file with the current encoding\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            \n",
    "            # Get the column names that contain HDI data (columns starting with 'hdi_')\n",
    "            hdi_columns = [col for col in df.columns if col.startswith('hdi_') and col != 'hdicode']\n",
    "            \n",
    "            # Create a list to store the data in the format (country_code, year, value)\n",
    "            hdi_data = []\n",
    "            \n",
    "            # Process each country\n",
    "            for _, row in df.iterrows():\n",
    "                iso3 = row['iso3']\n",
    "                country_name = row['country']\n",
    "                \n",
    "                # Process each year's HDI value\n",
    "                for col in hdi_columns:\n",
    "                    # Extract the year from the column name (format: hdi_YYYY)\n",
    "                    year = col.split('_')[1]\n",
    "                    \n",
    "                    # Try to convert to integer (handle cases like 'hdi_rank' if they exist)\n",
    "                    try:\n",
    "                        year = int(year)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    \n",
    "                    # Get the HDI value\n",
    "                    hdi_value = row[col]\n",
    "                    \n",
    "                    # Only add if the HDI value is not null\n",
    "                    if pd.notna(hdi_value):\n",
    "                        hdi_data.append({\n",
    "                            'code': iso3,\n",
    "                            'nome_pais': country_name,\n",
    "                            'ano': year,\n",
    "                            'valor': float(hdi_value)\n",
    "                        })\n",
    "            \n",
    "            # Convert list to DataFrame\n",
    "            hdi_df = pd.DataFrame(hdi_data)\n",
    "            print(f\"Successfully loaded HDI data with encoding: {encoding}\")\n",
    "            return hdi_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Failed with encoding {encoding}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # If all encodings fail\n",
    "    print(\"Error: Could not load HDI data with any of the attempted encodings\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to insert HDI data\n",
    "def insert_hdi_data(conn, df):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        inserted = 0\n",
    "        \n",
    "        # Filter out rows with NaN codes\n",
    "        df_clean = df.dropna(subset=['code'])\n",
    "        \n",
    "        # Get country_id mapping\n",
    "        country_ids = {}\n",
    "        cursor.execute(\"SELECT id_pais, code FROM Pais\")\n",
    "        for id_pais, code in cursor.fetchall():\n",
    "            country_ids[code] = id_pais\n",
    "        \n",
    "        # Add any missing countries\n",
    "        new_countries = []\n",
    "        for _, row in df_clean.iterrows():\n",
    "            if row['code'] not in country_ids:\n",
    "                new_countries.append((row['code'], row['nome_pais']))\n",
    "        \n",
    "        # Insert new countries if any\n",
    "        if new_countries:\n",
    "            new_countries_unique = list(set(new_countries))\n",
    "            for code, nome in new_countries_unique:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO Pais (code, nome)\n",
    "                    VALUES (%s, %s)\n",
    "                    RETURNING id_pais\n",
    "                    \"\"\",\n",
    "                    (code, nome)\n",
    "                )\n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    country_ids[code] = result[0]\n",
    "        \n",
    "        # Now insert HDI data\n",
    "        for _, row in df_clean.iterrows():\n",
    "            code = row['code']\n",
    "            id_pais = country_ids.get(code)\n",
    "            \n",
    "            if id_pais:\n",
    "                cursor.execute(\n",
    "                    \"\"\"\n",
    "                    INSERT INTO IDH (id_pais, ano, indice)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                    ON CONFLICT DO NOTHING\n",
    "                    RETURNING id\n",
    "                    \"\"\",\n",
    "                    (id_pais, row['ano'], row['valor'])\n",
    "                )\n",
    "                \n",
    "                result = cursor.fetchone()\n",
    "                if result:\n",
    "                    inserted += 1\n",
    "            else:\n",
    "                print(f\"Warning: No country ID found for HDI code {code}\")\n",
    "                \n",
    "        conn.commit()\n",
    "        print(f\"Inserted {inserted} HDI records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into IDH: {e}\")\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fbade",
   "metadata": {},
   "source": [
    "## 4. Database Server Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbaf308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while connecting to PostgreSQL: connection to server at \"127.0.0.1\", port 5433 failed: Connection refused\n",
      "\tIs the server running on that host and accepting TCP/IP connections?\n",
      "\n",
      "Failed to connect to the database.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the PostgreSQL database\n",
    "conn = connect_to_db()\n",
    "if conn:\n",
    "    print(\"Database connection established.\")\n",
    "else:\n",
    "    print(\"Failed to connect to the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af87272",
   "metadata": {},
   "source": [
    "## 5. Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d74269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating tables: 'NoneType' object has no attribute 'cursor'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cursor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError creating tables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mcursor\u001b[49m.close()\n",
      "\u001b[31mNameError\u001b[39m: name 'cursor' is not defined"
     ]
    }
   ],
   "source": [
    "# Read and execute the SQL script to create tables\n",
    "sql_file_path = DB_script_path\n",
    "\n",
    "try:\n",
    "    with open(sql_file_path, 'r') as file:\n",
    "        sql_script = file.read()\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_script)\n",
    "    conn.commit()\n",
    "    print(\"Tables created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating tables: {e}\")\n",
    "finally:\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407fb62",
   "metadata": {},
   "source": [
    "## 5. Add Data to Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05a588",
   "metadata": {},
   "source": [
    "### 5.1 Load and Insert `CAPACIDADE_GERACAO.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read with encoding: utf-8\n",
      "Successfully loaded data with encoding: utf-8\n",
      "Inserted/updated 28 states\n",
      "Inserted/updated 5 subsistemas\n",
      "Inserted/updated 30 subsistema-estado relationships\n",
      "Inserted 1441 agents\n",
      "Inserted 1896 power plants\n",
      "Inserted 5189 generating units\n"
     ]
    }
   ],
   "source": [
    "# Load and insert data from CAPACIDADE_GERACAO.csv\n",
    "cap_data = load_capacidade_geracao()\n",
    "if cap_data is not None:\n",
    "    insert_estado_and_subsistema_estado(conn, cap_data)\n",
    "    insert_agentes(conn, cap_data)\n",
    "    insert_usinas(conn, cap_data)\n",
    "    insert_unidades_geradoras(conn, cap_data)\n",
    "else:\n",
    "    print(\"Failed to load CAPACIDADE_GERACAO.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc37a61",
   "metadata": {},
   "source": [
    "### 5.2 Load and Insert Country Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc086f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 215 countries\n",
      "Inserted 6309 records into Acesso_Eletricidade\n",
      "Inserted 2 countries\n",
      "Inserted 6144 records into Acesso_Combustivel_Limpo\n",
      "Inserted 16 countries\n",
      "Inserted 4938 records into Acesso_Energia_Renovavel\n"
     ]
    }
   ],
   "source": [
    "# Load and insert country data\n",
    "country_files = [\n",
    "    ('share-of-the-population-with-access-to-electricity.csv', 'Access to electricity (% of population)', 'Acesso_Eletricidade'),\n",
    "    ('access-to-clean-fuels-and-technologies-for-cooking.csv', 'Proportion of population with primary reliance on clean fuels and technologies for cooking (%) - Residence area type: Total', 'Acesso_Combustivel_Limpo'),\n",
    "    ('share-of-final-energy-consumption-from-renewable-sources.csv', '7.2.1 - Renewable energy share in the total final energy consumption (%) - EG_FEC_RNEW', 'Acesso_Energia_Renovavel')\n",
    "]\n",
    "\n",
    "for file_name, value_column, table_name in country_files:\n",
    "    df = load_country_data(file_name, value_column)\n",
    "    if df is not None:\n",
    "        insert_paises(conn, df)\n",
    "        insert_country_data(conn, df, table_name)\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f425a6",
   "metadata": {},
   "source": [
    "### 5.3 Load and Insert Investment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdaa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1 countries\n",
      "Inserted 3519 investment records\n"
     ]
    }
   ],
   "source": [
    "# Load and insert investment data\n",
    "investment_file = 'international-finance-clean-energy.csv'\n",
    "investment_column = '7.a.1 - International financial flows to developing countries in support of clean energy research and development and renewable energy production, including in hybrid systems (millions of constant 2021 United States dollars) - EG_IFF_RANDN - All renewables'\n",
    "\n",
    "investment_data = load_country_data(investment_file, investment_column)\n",
    "if investment_data is not None:\n",
    "    insert_paises(conn, investment_data)\n",
    "    insert_investment_data(conn, investment_data)\n",
    "else:\n",
    "    print(\"Failed to load investment data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48b3d9",
   "metadata": {},
   "source": [
    "### 5.4 Load and Insert Renewable Capacity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cf65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 0 countries\n",
      "Inserted 5083 renewable per capita records\n"
     ]
    }
   ],
   "source": [
    "# Load and insert renewable capacity data\n",
    "renewable_file = 'renewable-electricity-generating-capacity-per-capita.csv'\n",
    "\n",
    "try:\n",
    "    capacity_df = pd.read_csv(os.path.join('./data', renewable_file))\n",
    "    capacity_column = capacity_df.columns[3]  # Assuming the fourth column contains the data\n",
    "    renewable_data = load_country_data(renewable_file, capacity_column)\n",
    "    if renewable_data is not None:\n",
    "        insert_paises(conn, renewable_data)\n",
    "        insert_renewable_per_capita(conn, renewable_data)\n",
    "    else:\n",
    "        print(\"Failed to load renewable capacity data.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing renewable capacity data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ccfeef",
   "metadata": {},
   "source": [
    "### 5.5 Load and Insert HDI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cbd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to read HDI data with encoding: latin-1\n",
      "Successfully loaded HDI data with encoding: latin-1\n",
      "Inserted 11 countries\n",
      "Inserted 6171 HDI records\n"
     ]
    }
   ],
   "source": [
    "# Load and insert HDI data\n",
    "hdi_data = load_hdi_data()\n",
    "if hdi_data is not None:\n",
    "    insert_paises(conn, hdi_data)\n",
    "    insert_hdi_data(conn, hdi_data)\n",
    "else:\n",
    "    print(\"Failed to load HDI data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9161bf",
   "metadata": {},
   "source": [
    "## 6. Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c17866",
   "metadata": {},
   "source": [
    "### 6.1 Comparison of Average Electricity Access: Brazil vs. Global Average\n",
    "\n",
    "This query compares Brazil's access to electricity with the global average over time. The medias CTE calculates the global average percentage of access to electricity per year, while the brasil CTE retrieves Brazil's yearly data. The final query joins these results by year, showing Brazil's percentage alongside the global average, ordered chronologically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14717990",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "WITH media_mundial AS (\n",
    "    SELECT \n",
    "        ano,\n",
    "        AVG(porcentagem) AS media_global\n",
    "    FROM \n",
    "        Acesso_Eletricidade\n",
    "    GROUP BY \n",
    "        ano\n",
    "),\n",
    "brasil AS (\n",
    "    SELECT \n",
    "        ae.ano,\n",
    "        ae.porcentagem AS acesso_brasil\n",
    "    FROM \n",
    "        Acesso_Eletricidade ae\n",
    "    JOIN \n",
    "        Pais p ON ae.id_pais = p.id_pais\n",
    "    WHERE \n",
    "        p.nome = 'Brazil'\n",
    ")\n",
    "SELECT \n",
    "    b.ano,\n",
    "    b.acesso_brasil,\n",
    "    m.media_global\n",
    "FROM \n",
    "    brasil b\n",
    "JOIN \n",
    "    media_mundial m ON b.ano = m.ano\n",
    "ORDER BY \n",
    "    b.ano;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3003cb",
   "metadata": {},
   "source": [
    "### 6.2 Top 10 Countries with Renwable Energy\n",
    "\n",
    "This query retrieves the top 10 countries with the highest renewable energy share in a specific year (here the example is with 2020), ranking them by percentage in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56046459",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"\"\"\n",
    "WITH ano_escolhido AS (\n",
    "  SELECT 2020 AS ano  -- substitua por qualquer ano disponÃ­vel\n",
    ")\n",
    "SELECT\n",
    "  p.nome      AS pais,\n",
    "  a.ano,\n",
    "  a.porcentagem AS pct_renovavel\n",
    "FROM\n",
    "  Acesso_Energia_Renovavel AS a\n",
    "  JOIN Pais AS p\n",
    "    ON a.id_pais = p.id_pais\n",
    "  JOIN ano_escolhido AS x\n",
    "    ON a.ano = x.ano\n",
    "ORDER BY\n",
    "  a.porcentagem DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c1f45",
   "metadata": {},
   "source": [
    "### 6.3 Correlation between HDI and Renewable Energy Generation per Capita\n",
    "\n",
    "This query calculates the correlation between the Human Development Index (HDI) and renewable energy generation per capita for each year. It joins the IDH and Energia_Renovavel_Per_Capita tables on country and year, computes the correlation coefficient (CORR), and groups the results by year, displaying them in chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381388c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = \"\"\"\n",
    "SELECT\n",
    "  i.ano,\n",
    "  CORR(i.indice, e.geracao_watts) AS correlacao_idh_geracao\n",
    "FROM\n",
    "  IDH AS i\n",
    "  JOIN Energia_Renovavel_Per_Capita AS e\n",
    "    ON i.id_pais = e.id_pais\n",
    "   AND i.ano     = e.ano\n",
    "GROUP BY\n",
    "  i.ano\n",
    "ORDER BY\n",
    "  i.ano;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a81d7",
   "metadata": {},
   "source": [
    "### 6.4 Agents with Multiple Power Plants in Brazil\n",
    "\n",
    "This query identifies agents who own more than one power plant. It counts the total number of plants (total_usinas) owned by each agent, groups the results by agent name, filters for agents with more than one plant, and orders the results in descending order of plant count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b05174",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4 = \"\"\"\n",
    "SELECT\n",
    "  ap.nome                AS agente,\n",
    "  COUNT(u.id_usina)      AS total_usinas\n",
    "FROM\n",
    "  Agente_Proprietario AS ap\n",
    "  JOIN Usina AS u\n",
    "    ON ap.id_agente = u.id_agente_proprietario\n",
    "GROUP BY\n",
    "  ap.nome\n",
    "HAVING\n",
    "  COUNT(u.id_usina) > 1\n",
    "ORDER BY\n",
    "  total_usinas DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b63851",
   "metadata": {},
   "source": [
    "### 6.5 Power Plants by Fuel Type in Brazil\n",
    "\n",
    "This query identifies the types of fuel used by power plants in Brazil and counts the number of distinct power plants (qtd_usinas) for each fuel type. It groups the results by fuel type, filters for power plants located in Brazil, and orders the results in descending order of the number of power plants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_5 = \"\"\"\n",
    "SELECT\n",
    "  ug.combustivel,\n",
    "  COUNT(DISTINCT u.id_usina) AS qtd_usinas\n",
    "FROM\n",
    "  Unidade_Geradora ug\n",
    "  JOIN Usina u ON ug.id_usina = u.id_usina\n",
    "  JOIN Estado est ON u.id_estado = est.id_estado\n",
    "  JOIN Subsistema_Estado se ON est.id_estado = se.id_estado\n",
    "  JOIN Subsistema s ON se.id_subsistema = s.id_subsistema\n",
    "  JOIN Pais p ON s.id_pais = p.id_pais\n",
    "WHERE\n",
    "  p.nome = 'Brazil'\n",
    "GROUP BY\n",
    "  ug.combustivel\n",
    "ORDER BY\n",
    "  qtd_usinas DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28423952",
   "metadata": {},
   "source": [
    "### 6.6 Total Power Generation Capacity by State in Brazil\n",
    "\n",
    "This query calculates the total power generation capacity (capacidade_total_mw) for each state in Brazil. It aggregates the effective power (potencia_efetiva) of all generating units, groups the results by state, and orders them in descending order of total capacity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_6 = \"\"\"\n",
    "SELECT\n",
    "  est.nome AS estado,\n",
    "  SUM(ug.potencia_efetiva) AS capacidade_total_mw\n",
    "FROM\n",
    "  Unidade_Geradora ug\n",
    "  JOIN Usina u ON ug.id_usina = u.id_usina\n",
    "  JOIN Estado est ON u.id_estado = est.id_estado\n",
    "  JOIN Subsistema_Estado se ON est.id_estado = se.id_estado\n",
    "  JOIN Subsistema s ON se.id_subsistema = s.id_subsistema\n",
    "  JOIN Pais p ON s.id_pais = p.id_pais\n",
    "WHERE\n",
    "  p.nome = 'Brazil'\n",
    "GROUP BY\n",
    "  est.nome\n",
    "ORDER BY\n",
    "  capacidade_total_mw DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee2182",
   "metadata": {},
   "source": [
    "### 6.7 Percentage of renewable vs. non-renewable power plants by state\n",
    "\n",
    "This query calculates the percentage of renewable energy power plants in each state of Brazil. It first determines the total number of power plants (total_usinas) and the number of renewable energy power plants (usinas_renovaveis) for each state. Renewable energy sources include biomass, solar, wind, and hydroelectric. The final result includes the state name, total power plants, renewable power plants, and the percentage of renewable power plants, ordered by the percentage in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f64da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_7 = \"\"\"\n",
    "WITH tot_estado AS (\n",
    "  SELECT\n",
    "    est.id_estado,\n",
    "    est.nome AS estado,\n",
    "    COUNT(u.id_usina) AS total_usinas\n",
    "  FROM Usina u\n",
    "    JOIN Estado est ON u.id_estado = est.id_estado\n",
    "    JOIN Subsistema_Estado se ON est.id_estado = se.id_estado\n",
    "    JOIN Subsistema s ON se.id_subsistema = s.id_subsistema\n",
    "    JOIN Pais p ON s.id_pais = p.id_pais\n",
    "  WHERE p.nome = 'Brazil'\n",
    "  GROUP BY est.id_estado, est.nome\n",
    "), ren_estado AS (\n",
    "  SELECT\n",
    "    est.id_estado,\n",
    "    COUNT(DISTINCT u.id_usina) AS usinas_renovaveis\n",
    "  FROM Unidade_Geradora ug\n",
    "    JOIN Usina u ON ug.id_usina = u.id_usina\n",
    "    JOIN Estado est ON u.id_estado = est.id_estado\n",
    "    JOIN Subsistema_Estado se ON est.id_estado = se.id_estado\n",
    "    JOIN Subsistema s ON se.id_subsistema = s.id_subsistema\n",
    "    JOIN Pais p ON s.id_pais = p.id_pais\n",
    "  WHERE\n",
    "    p.nome = 'Brazil'\n",
    "    AND ug.combustivel IN ('BIOMASSA', 'SOLAR', 'EÃLICA', 'HÃDRICA')  -- exemplo de renovÃ¡veis\n",
    "  GROUP BY est.id_estado\n",
    ")\n",
    "SELECT\n",
    "  t.estado,\n",
    "  t.total_usinas,\n",
    "  COALESCE(r.usinas_renovaveis, 0) AS usinas_renovaveis,\n",
    "  ROUND(\n",
    "    COALESCE(r.usinas_renovaveis, 0)::decimal\n",
    "    / t.total_usinas * 100\n",
    "  , 2) AS perc_renovaveis\n",
    "FROM\n",
    "  tot_estado t\n",
    "  LEFT JOIN ren_estado r ON t.id_estado = r.id_estado\n",
    "ORDER BY\n",
    "  perc_renovaveis DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d5bc3",
   "metadata": {},
   "source": [
    "## 7 Function to Run and Save Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847caac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for query results\n",
    "OUTPUT_DIR = './query_results'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "queries = {\n",
    "    'query_1': query_1,\n",
    "    'query_2': query_2,\n",
    "    'query_3': query_3,\n",
    "    'query_4': query_4,\n",
    "    'query_5': query_5,\n",
    "    'query_6': query_6,\n",
    "    'query_7': query_7\n",
    "}\n",
    "\n",
    "# Function to run queries and save results to CSV\n",
    "def run_queries_and_save(queries):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        for query_name, query in queries.items():\n",
    "            print(f\"Running {query_name}...\")\n",
    "            cursor.execute(query)\n",
    "            # Fetch all results\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            rows = cursor.fetchall()\n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(rows, columns=columns)\n",
    "            # Save to CSV\n",
    "            output_path = os.path.join(OUTPUT_DIR, f\"{query_name}.csv\")\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved {query_name} results to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764377f5",
   "metadata": {},
   "source": [
    "## 8 Run and Save Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query_1...\n",
      "Saved query_1 results to ./query_results/query_1.csv\n",
      "Running query_2...\n",
      "Saved query_2 results to ./query_results/query_2.csv\n",
      "Running query_3...\n",
      "Saved query_3 results to ./query_results/query_3.csv\n",
      "Running query_4...\n",
      "Saved query_4 results to ./query_results/query_4.csv\n",
      "Running query_5...\n",
      "Saved query_5 results to ./query_results/query_5.csv\n",
      "Running query_6...\n",
      "Saved query_6 results to ./query_results/query_6.csv\n",
      "Running query_7...\n",
      "Saved query_7 results to ./query_results/query_7.csv\n"
     ]
    }
   ],
   "source": [
    "run_queries_and_save(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15824d4e",
   "metadata": {},
   "source": [
    "## 9 Close Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Close the database connection\n",
    "if cursor:\n",
    "    cursor.close()\n",
    "if conn:\n",
    "    conn.close()\n",
    "print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
